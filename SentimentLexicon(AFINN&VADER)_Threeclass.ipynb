{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNbduXBhPRdZh15SVehGupX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohanZhu0623/Sentiment_Analysis/blob/main/SentimentLexicon(AFINN%26VADER)_Threeclass.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNsine51Zflj",
        "outputId": "0579ff5e-87cd-4292-c842-e2c12d1eb9f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: afinn in /usr/local/lib/python3.10/dist-packages (0.1)\n",
            "Collecting vaderSentiment\n",
            "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vaderSentiment) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (2024.7.4)\n",
            "Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install afinn\n",
        "!pip install vaderSentiment\n",
        "import pandas as pd\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from afinn import Afinn\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "0nPkT9NsaSIN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjhZnIXRaHNz",
        "outputId": "9bde4707-b26e-49b3-fae7-008e935c1aa4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "data = pd.read_excel('/content/python_labelled_data.xlsx')"
      ],
      "metadata": {
        "id": "7N-JGn9DZgtt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess data\n",
        "def pre_process_data(dataset):\n",
        "    # Convert to lowercase\n",
        "    dataset['text'] = dataset['text'].str.lower()\n",
        "    # Remove numbers\n",
        "    dataset['text'] = dataset['text'].str.replace(r'\\d+', '', regex=True)\n",
        "    # Remove punctuation\n",
        "    dataset['text'] = dataset['text'].str.replace(f\"[{string.punctuation}]\", \"\", regex=True)\n",
        "    # Remove whitespace\n",
        "    dataset['text'] = dataset['text'].str.strip()\n",
        "    # Remove stopwords except 'not'\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    stop_words.remove('not')\n",
        "    dataset['text'] = dataset['text'].apply(lambda x: ' '.join([word for word in word_tokenize(x) if word not in stop_words]))\n",
        "    return dataset\n",
        "\n",
        "# Apply preprocessing to the data\n",
        "data = pre_process_data(data)\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjKSWE3maAsD",
        "outputId": "799ec1d5-1ac6-471d-c4e5-1f1f5ff820f9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text  class\n",
            "0  project designed help protect environment usin...      1\n",
            "1  help us built sustainable studio eliminate cla...      1\n",
            "2  paint something dont want explain isbob ross b...      0\n",
            "3  free app allow pool reservations others get gr...      1\n",
            "4  prohibition themed gastro pub dark silent head...      1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the labeled data into training set (80%) and hold-out test set (20%)\n",
        "partition = 0.8\n",
        "train_data, test_data = train_test_split(data, test_size=1-partition, random_state=128, stratify=data['class'])\n",
        "print(f\"Training set size: {train_data.shape}\")\n",
        "print(f\"Test set size: {test_data.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4c34zbSaqjT",
        "outputId": "efb05d2e-4520-4c60-9f17-2353349d181b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: (1815, 2)\n",
            "Test set size: (454, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to classify text using AFINN\n",
        "afinn = Afinn()\n",
        "\n",
        "def classify_afinn(text):\n",
        "    score = afinn.score(text)\n",
        "    if score > 0:\n",
        "        return 1\n",
        "    elif score < 0:\n",
        "        return -1\n",
        "    else:\n",
        "        return 0"
      ],
      "metadata": {
        "id": "7rSri_6uaat5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to classify text using VADER\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "def classify_vader(text):\n",
        "    scores = analyzer.polarity_scores(text)\n",
        "    compound = scores['compound']\n",
        "    if compound > 0.05:\n",
        "        return 1\n",
        "    elif compound < -0.05:\n",
        "        return -1\n",
        "    else:\n",
        "        return 0"
      ],
      "metadata": {
        "id": "eha36Q4Racy0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply classification to the test set using AFINN\n",
        "test_data['afinn_predicted'] = test_data['text'].apply(classify_afinn)\n",
        "\n",
        "# Apply classification to the test set using VADER\n",
        "test_data['vader_predicted'] = test_data['text'].apply(classify_vader)"
      ],
      "metadata": {
        "id": "Ls3pK5_3aevY"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate metrics for AFINN\n",
        "afinn_accuracy = accuracy_score(test_data['class'], test_data['afinn_predicted'])\n",
        "afinn_precision = precision_score(test_data['class'], test_data['afinn_predicted'], average='weighted')\n",
        "afinn_recall = recall_score(test_data['class'], test_data['afinn_predicted'], average='weighted')\n",
        "afinn_f1 = f1_score(test_data['class'], test_data['afinn_predicted'], average='weighted')\n",
        "\n",
        "# Calculate metrics for VADER\n",
        "vader_accuracy = accuracy_score(test_data['class'], test_data['vader_predicted'])\n",
        "vader_precision = precision_score(test_data['class'], test_data['vader_predicted'], average='weighted')\n",
        "vader_recall = recall_score(test_data['class'], test_data['vader_predicted'], average='weighted')\n",
        "vader_f1 = f1_score(test_data['class'], test_data['vader_predicted'], average='weighted')\n",
        "\n",
        "# Print the results\n",
        "print(\"AFINN Metrics:\")\n",
        "print(f\"Accuracy: {afinn_accuracy}\")\n",
        "print(f\"Precision: {afinn_precision}\")\n",
        "print(f\"Recall: {afinn_recall}\")\n",
        "print(f\"F1 Score: {afinn_f1}\")\n",
        "\n",
        "print(\"\\nVADER Metrics:\")\n",
        "print(f\"Accuracy: {vader_accuracy}\")\n",
        "print(f\"Precision: {vader_precision}\")\n",
        "print(f\"Recall: {vader_recall}\")\n",
        "print(f\"F1 Score: {vader_f1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oup6D7wawq0",
        "outputId": "22883da4-04df-4270-af24-7e681856e275"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AFINN Metrics:\n",
            "Accuracy: 0.6013215859030837\n",
            "Precision: 0.6093346123584772\n",
            "Recall: 0.6013215859030837\n",
            "F1 Score: 0.5909687502472332\n",
            "\n",
            "VADER Metrics:\n",
            "Accuracy: 0.6167400881057269\n",
            "Precision: 0.6449829758707675\n",
            "Recall: 0.6167400881057269\n",
            "F1 Score: 0.5923037072296562\n"
          ]
        }
      ]
    }
  ]
}